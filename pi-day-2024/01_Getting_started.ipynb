{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331d43e6-031d-4dc3-ba24-eeb453a14055",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h1 style=\"color: #347AB7;\">Getting Started with Amazon <code style=\"background-color: #f5f5f5; color: #EB5424;\">Bedrock</code></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d55a7d-204a-4738-904a-2da5a695fb82",
   "metadata": {},
   "source": [
    "With the Amazon `Bedrock` serverless experience, you can quickly get started, easily experiment with FMs, privately customize FMs with your own data, and seamlessly integrate and deploy them into your applications using AWS tools and capabilities.\n",
    "\n",
    "**Foundation models**\n",
    "\n",
    "Amazon Bedrock supports foundation models from industry-leading providers. Choose the model that is best suited to achieving your unique goals.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/fms.png\" alt=\"Claude 3 Benchmark\" style=\"width: 80%;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663824a5-17c9-4d6a-815f-a53f0dbae00e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h1 style=\"color: #347AB7;\">Introduction to <code style=\"background-color: #f5f5f5; color: #EB5424;\">Claude 3</code> on Amazon <code style=\"background-color: #f5f5f5; color: #EB5424;\">Bedrock</code></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c09326-f573-40a9-8f90-d02e2ea1a010",
   "metadata": {},
   "source": [
    "<p>Anthropic is proud to announce <strong style=\"color: #347AB7;\">Claude 3</strong>, a new family of state-of-the-art AI models that redefine the possibilities for customizing artificial intelligence to meet specific business needs. This innovative offering allows customers to select the perfect blend of intelligence, speed, and cost-effectiveness for their unique requirements. The Claude 3 family consists of three distinct models:</p>\n",
    "\n",
    "<ul>\n",
    "    <li><strong>Claude 3 <code style=\"background-color: #f5f5f5; color: #EB5424;\">Haiku</code></strong>: The epitome of efficiency and speed. Designed for near-instant responsiveness, Haiku is the fastest and most compact model, perfect for applications requiring immediate feedback without compromising on performance.</li>\n",
    "    <li><strong>Claude 3 <code style=\"background-color: #f5f5f5; color: #EB5424;\">Sonnet</code></strong>: The ideal compromise. Sonnet offers a balanced mix of capabilities and speed, making it the go-to model for businesses seeking a harmonious blend of performance and efficiency.</li>\n",
    "    <li><strong>Claude 3 <code style=\"background-color: #f5f5f5; color: #EB5424;\">Opus</code></strong>: The pinnacle of intelligence. Opus is engineered for top-level performance on the most complex tasks, offering unparalleled intelligence and capability for the most demanding business applications.</li>\n",
    "</ul>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/claude3_bm.png\" alt=\"Claude 3 Benchmark\" style=\"width: 50%;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdea909-83eb-4aac-8580-b5eb6a06641d",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #347AB7;\">Now Available in Amazon Bedrock</h2>\n",
    "\n",
    "<p><strong style=\"color: #347AB7;\">Anthropic’s Claude 3 Sonnet</strong> is now available in Amazon Bedrock, with Claude 3 Opus and Claude 3 Haiku coming soon. The integration of Claude 3 Sonnet within Amazon Bedrock paves the way for the development of cost-effective, intelligent, reliable, and speedy generative AI applications tailored for enterprise needs.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799230e-e223-4a3a-9e87-0c41d693a4ba",
   "metadata": {},
   "source": [
    "Let's get started with Claude using Bedrock. \n",
    "- Amazon Bedrock `UI` \n",
    "- AWS SDK using `boto3`\n",
    "- Deploy your **own chatbot** using Amazon Bedrock deployed on `AWS`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb93100-3b11-4e37-b796-e7b8dc3a4495",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style=\"color: #D35400;\">Amazon Bedrock UI</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9197ff-b6f5-41f4-94e2-c994877356a2",
   "metadata": {},
   "source": [
    "Let's jump into the [Amazon Bedrock Console](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cabda5-ed74-4d41-bbb2-2662140358b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style=\"color: #D35400;\">AWS SDK using boto3</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5add282-3520-4c30-a62c-324751efdb2f",
   "metadata": {},
   "source": [
    "Now, let's use the AWS Python SDK `boto3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab536f45-a505-4341-83d4-a2cf64039b88",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a `bedrock` client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc42da1-a040-4de2-bf1e-ed08ef3ad5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "\n",
    "\n",
    "\n",
    "#Create the connection to Bedrock\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock',\n",
    "    region_name='us-west-2', \n",
    ")\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-west-2', \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac6718-0a38-40c1-a31d-0bc6d8301e22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With `Anthropic (Claude v3 (Sonnet))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357de4b-8c0d-4317-b14e-b099adbe722c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"What is L in LLM means\"\"\"\n",
    "\n",
    "body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 1024,\n",
    "            \"messages\": [\n",
    "                 {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt_data\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "body = json.dumps(body) # Encode body as JSON string\n",
    "\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8cb2f-0478-4697-86d0-590fbf8be22d",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c204dee-e262-4c40-becf-8af9255f6145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(body=body,\n",
    "                                        modelId=model_id, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de6d86-bff5-4a73-a2ff-c7ec38c49d81",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2e98a-515f-4896-89fe-d96f1e4b00c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "for output in response_body.get(\"content\", []):\n",
    "    print(output[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656ce38-e3dd-492f-b035-8a708cbe34b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Syntax Multi-Modal models from `Anthropic Claude v3 Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dcda90-954d-4c0c-92a2-cb2479f0adb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"images/cat.png\", \"rb\") as image_file:\n",
    "    encoded_string = base64.b64encode(image_file.read())\n",
    "    base64_string = encoded_string.decode('utf-8')\n",
    "\n",
    "payload = {\n",
    "    \"modelId\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"contentType\": \"application/json\",\n",
    "    \"accept\": \"application/json\",\n",
    "    \"body\": {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/png\",\n",
    "                            \"data\": base64_string\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Write me a detailed description of this photo.\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert the payload to bytes\n",
    "body_bytes = json.dumps(payload['body']).encode('utf-8')\n",
    "\n",
    "# Invoke the model\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock_runtime.invoke_model(body=body_bytes,\n",
    "                                        modelId=model_id, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3482f6-bfa5-4006-867e-e5a35a089e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_body = json.loads(response.get('body').read().decode('utf-8'))\n",
    "print(response_body.get('content')[0].get('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f57584-eca6-4602-a6a6-ab39528d13c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69b918e6-78a1-4426-813a-0608892089bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### List of all available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d421313-4275-4ab2-824c-ebd543345574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List all foundation models\n",
    "all_llms = [ model['modelId'] for model in bedrock.list_foundation_models()['modelSummaries']]\n",
    "all_llms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f983c62-5db4-4939-99cd-01ed5cf50ece",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### With `Mistral (mixtral-8x7b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9fd10c-b83f-45c4-9e1a-9b55e1736354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"<s>[INST]Craft a Python function to convert Celsius to Fahrenheit. If water boils at 100°C, what's that in Fahrenheit?[/INST]\"\"\"\n",
    "\n",
    "body = json.dumps({ \n",
    "    'prompt': prompt_data,\n",
    "    'max_tokens': 200,\n",
    "    'top_p': 0.9,\n",
    "    'temperature': 0.2,\n",
    "})\n",
    "\n",
    "\n",
    "modelId = 'mistral.mixtral-8x7b-instruct-v0:1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83e979-9d72-4ab7-9acb-3afc89687213",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285cc8b-b9df-4339-8b69-8e9594a8e9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(body=body.encode('utf-8'), # Encode to bytes\n",
    "                                        modelId=modelId, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15918b5d-1068-4d93-9309-c1d3f2e903b6",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e49eef-0d1b-43c2-a6a6-5a8aca398db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_body = json.loads(response.get('body').read().decode('utf-8'))\n",
    "print(response_body.get('outputs')[0].get('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4424ed56-7725-4b51-b027-ee53b2de1b48",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With `Amazon Titan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a9ba82-62d6-49bd-ac1e-967d5bc59d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"Write me a poem about apples\"\"\"\n",
    "\n",
    "text_gen_config = {\n",
    "                    \"maxTokenCount\": 512,\n",
    "                    \"stopSequences\": [], \n",
    "                    \"temperature\": 0,\n",
    "                    \"topP\": 0.9\n",
    "                }\n",
    "\n",
    "body = json.dumps({\n",
    "                        \"inputText\": prompt_data,\n",
    "                        \"textGenerationConfig\": text_gen_config  \n",
    "                    })\n",
    "\n",
    "model_id = 'amazon.titan-tg1-large'\n",
    "accept = 'application/json' \n",
    "content_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc650c9-a75c-4ed4-ae0a-e3e0a5e38914",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3702c51b-a622-4635-aeb7-e3309013ef29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "                                            body=body, \n",
    "                                            modelId=model_id, \n",
    "                                            accept=accept, \n",
    "                                            contentType=content_type\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e7285-e061-4886-934f-904da5d43fa7",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be453a-62d5-400e-aca1-f3b1beb0dd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_body = json.loads(response['body'].read())\n",
    "print(response_body['results'][0]['outputText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df4096-baca-49b0-a712-c23ef975b70f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style=\"color: #D35400;\">Deploy your own <code style=\"background-color: #f5f5f5; color: #EB5444;\">chatbot</code>  using Amazon Bedrock deployed on AWS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad8af4-fca7-4d83-a890-d1f8215519e9",
   "metadata": {},
   "source": [
    "### Demo\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/chatbodbedrock.gif\" alt=\"Claude 3 Benchmark\" style=\"width: 100%;\"/>\n",
    "</div>\n",
    "\n",
    "### Architecture\n",
    "\n",
    "It's an architecture built on AWS managed services, eliminating the need for infrastructure management. Utilizing Amazon Bedrock, there's no need to communicate with APIs outside of AWS. This enables deploying scalable, reliable, and secure applications.\n",
    "\n",
    "- [Amazon DynamoDB](https://aws.amazon.com/dynamodb/): NoSQL database for conversation history storage\n",
    "- [Amazon API Gateway](https://aws.amazon.com/api-gateway/) + [AWS Lambda](https://aws.amazon.com/lambda/): Backend API endpoint ([AWS Lambda Web Adapter](https://github.com/awslabs/aws-lambda-web-adapter), [FastAPI](https://fastapi.tiangolo.com/))\n",
    "- [Amazon CloudFront](https://aws.amazon.com/cloudfront/) + [S3](https://aws.amazon.com/s3/): Frontend application delivery ([React](https://react.dev/), [Tailwind CSS](https://tailwindcss.com/))\n",
    "- [AWS WAF](https://aws.amazon.com/waf/): IP address restriction\n",
    "- [Amazon Cognito](https://aws.amazon.com/cognito/): User authentication\n",
    "- [Amazon Bedrock](https://aws.amazon.com/bedrock/): Managed service to utilize foundational models via APIs. Claude is used for chat response and Cohere for vector embedding\n",
    "- [Amazon EventBridge Pipes](https://aws.amazon.com/eventbridge/pipes/): Receiving event from DynamoDB stream and launching ECS task to embed external knowledge\n",
    "- [Amazon Elastic Container Service](https://aws.amazon.com/ecs/): Run crawling, parsing and embedding tasks. [Cohere Multilingual](https://txt.cohere.com/multilingual/) is the model used for embedding.\n",
    "- [Amazon Aurora PostgreSQL](https://aws.amazon.com/rds/aurora/): Scalable vector store with [pgvector](https://github.com/pgvector/pgvector) plugin\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/arch.png\" alt=\"Architecture\" style=\"width: 70%;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf6d99-78ae-48f2-81a2-53d3e9aaeb89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
